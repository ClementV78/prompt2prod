# Prompt2Prod

## ğŸ¯ Vue d'ensemble

**Prompt2Prod** est un systÃ¨me DevOps qui gÃ©nÃ¨re du code Ã  partir de prompts en langage naturel en utilisant une architecture cloud-native moderne.

### FonctionnalitÃ©s

- **GÃ©nÃ©ration de code** via modÃ¨les Ollama locaux
- **API moderne** FastAPI avec documentation Swagger
- **Architecture Kubernetes** cloud-native
- **Pipeline CI/CD** avec GitHub Actions
- **Routage intelligent** via KGateway (CNCF Gateway API)

## ğŸš€ DÃ©marrage rapide

```bash
# 1. Cloner le repository
git clone https://github.com/ClementV78/prompt2prod.git
cd prompt2prod

# 2. Setup infrastructure
./scripts/setup-k3s.sh          # Setup cluster Kubernetes
./scripts/setup-kgateway.sh     # Setup Gateway API
./scripts/deploy.sh             # DÃ©ployer les services

# 3. Charger les modÃ¨les IA
./scripts/setup-ollama-models.sh

# 4. Tester l'API
curl -X POST "http://localhost:8080/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a Python hello world script", "model": "llama3.2:1b", "mode": "local"}'
```

## ğŸ“‹ PrÃ©requis

- Docker
- kubectl 
- k3s (ou cluster Kubernetes)
- Python 3.11+

```bash
# Dependencies Python
pip install -r requirements.txt
pip install -r requirements-test.txt  # Pour les tests
```

## ğŸ“ Structure

```
prompt2prod/
â”œâ”€â”€ .github/workflows/     # CI/CD GitHub Actions
â”œâ”€â”€ src/api/              # API FastAPI
â”œâ”€â”€ k8s/base/             # Manifests Kubernetes  
â”œâ”€â”€ docker/               # Dockerfile
â”œâ”€â”€ scripts/              # Scripts d'automatisation
â”œâ”€â”€ tests/                # Tests unitaires
â””â”€â”€ docs/                 # Documentation complÃ¨te
```

## ğŸ› ï¸ Architecture technique

### Stack technologique

- **API**: FastAPI avec validation Pydantic
- **IA**: Ollama local (Llama3.2, Mistral, CodeLlama)
- **Orchestration**: Kubernetes avec K3s
- **Routage**: KGateway (CNCF Gateway API)
- **CI/CD**: GitHub Actions + GHCR
- **Containerisation**: Docker multi-stage builds

### Architecture

```
User â†’ FastAPI â†’ Ollama â†’ Generated Code
  â†“
GitHub Actions â†’ GHCR â†’ Kubernetes
```

### Composants dÃ©ployÃ©s

- **FastAPI App**: API de gÃ©nÃ©ration de code
- **Ollama**: Service IA local 
- **KGateway**: Routage et load balancing
- **Monitoring**: Health checks et observabilitÃ©

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration
./scripts/test.sh

# Test API direct
curl http://localhost:8080/health
```

## ğŸ“Š Monitoring

```bash
# Status des pods
kubectl get pods -A

# Logs de l'application
kubectl logs -f deployment/app

# Logs Ollama
kubectl logs -f deployment/ollama

# Models disponibles
kubectl exec deployment/ollama -- ollama list
```

## ğŸ“ Documentation

- **[ğŸ—ï¸ Architecture](docs/html/architecture.html)** - Guide DevOps complet
- **[ğŸ”Œ API Reference](docs/html/api-reference.html)** - Documentation des endpoints
- **[ğŸ‘¤ Guide Utilisateur](docs/html/user-guide.html)** - Guide fonctionnel
- **[ğŸ“– Documentation complÃ¨te](docs/html/index.html)** - Interface d'accueil

## ğŸ”§ DÃ©veloppement

```bash
# DÃ©ploiement local
kubectl apply -f k8s/base/

# Rebuild et redÃ©ploiement
docker build -t ghcr.io/clementv78/prompt2prod:latest -f docker/Dockerfile .
kubectl rollout restart deployment/app

# AccÃ¨s aux logs
kubectl logs -f deployment/app
```

## âš¡ Exemple d'utilisation

```bash
# GÃ©nÃ©ration simple
curl -X POST "http://localhost:8080/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a Python FastAPI hello world",
    "model": "llama3.2:1b", 
    "mode": "local"
  }'

# Interface Swagger
open http://localhost:8080/docs
```

## ğŸ“„ Licence

MIT

## ğŸš€ Status

âœ… **Production Ready** - Architecture DevOps moderne avec patterns cloud-native

---

**Note**: Ce projet dÃ©montre une architecture DevOps complÃ¨te intÃ©grant l'IA locale sans dÃ©pendances externes payantes.
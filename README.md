# Prompt2Prod

## ğŸ¯ Vue d'ensemble

**Prompt2Prod** est un systÃ¨me DevOps qui gÃ©nÃ¨re du code Ã  partir de prompts en langage naturel en utilisant une architecture cloud-native moderne.

### FonctionnalitÃ©s

- **GÃ©nÃ©ration de code** via modÃ¨les Ollama locaux
- **API moderne** FastAPI avec documentation Swagger
- **Architecture Kubernetes** cloud-native
- **Pipeline CI/CD** avec GitHub Actions
- **Routage intelligent** via KGateway (CNCF Gateway API)

## ğŸš€ DÃ©marrage rapide

```bash
# 1. Cloner le repository
git clone https://github.com/ClementV78/prompt2prod.git
cd prompt2prod

# 2. Setup infrastructure (one-time)
./scripts/setup-k3s.sh          # Setup cluster Kubernetes
./scripts/setup-kgateway.sh     # Setup Gateway API
./scripts/setup-ollama-models.sh # Charger les modÃ¨les IA

# 3. DÃ©ployer l'application
kubectl apply -R -f k8s/base/

# 4. Tester l'API
curl -X POST "http://192.168.31.106:31104/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a Python hello world script", "model": "llama3.2:1b", "mode": "local"}'
```

## ğŸ“‹ PrÃ©requis

- Docker
- kubectl 
- k3s (ou cluster Kubernetes)
- Python 3.11+

```bash
# Dependencies Python
pip install -r requirements.txt
pip install -r requirements-test.txt  # Pour les tests
```

## ğŸ“ Structure

```
prompt2prod/
â”œâ”€â”€ .github/workflows/     # CI/CD GitHub Actions
â”œâ”€â”€ src/api/              # API FastAPI
â”œâ”€â”€ k8s/base/             # Manifests Kubernetes  
â”œâ”€â”€ docker/               # Dockerfile
â”œâ”€â”€ scripts/              # Scripts d'automatisation
â”œâ”€â”€ tests/                # Tests unitaires
â””â”€â”€ docs/                 # Documentation complÃ¨te
```

## ğŸ› ï¸ Architecture technique

### Stack technologique

- **API**: FastAPI avec validation Pydantic
- **IA**: Ollama local (Llama3.2:1b, phi3:mini, mistral:7b-instruct) + Cloud (OpenAI)
- **Orchestration**: Kubernetes avec K3s
- **Routage**: KGateway (CNCF Gateway API)
- **CI/CD**: GitHub Actions + GHCR
- **Containerisation**: Docker multi-stage builds

### Architecture

```
User â†’ FastAPI â†’ KGateway â†’ [Local: Ollama | Cloud: OpenAI] â†’ Generated Code
                    â†“ (unified routing)
           [llama3.2:1b, phi3:mini, mistral:7b] | [gpt-4o-mini, gpt-3.5-turbo]
```

### Composants dÃ©ployÃ©s

- **FastAPI App**: API de gÃ©nÃ©ration de code
- **Ollama**: Service IA local 
- **KGateway**: Routage et load balancing
- **Monitoring**: Health checks et observabilitÃ©

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration
./scripts/test.sh

# Test API direct
curl http://localhost:8080/health
```

## ğŸ“Š Monitoring

```bash
# Status des pods
kubectl get pods -A

# Logs de l'application
kubectl logs -f deployment/app

# Logs Ollama
kubectl logs -f deployment/ollama

# Models disponibles
kubectl exec deployment/ollama -- ollama list
```

## ğŸ“ Documentation

- **[ğŸ—ï¸ Architecture](https://htmlpreview.github.io/?https://github.com/ClementV78/prompt2prod/blob/main/docs/html/architecture.html)** - Guide DevOps complet
- **[ğŸ”Œ API Reference](https://htmlpreview.github.io/?https://github.com/ClementV78/prompt2prod/blob/main/docs/html/api-reference.html)** - Documentation des endpoints
- **[ğŸ‘¤ Guide Utilisateur](https://htmlpreview.github.io/?https://github.com/ClementV78/prompt2prod/blob/main/docs/html/user-guide.html)** - Guide fonctionnel
- **[ğŸ“– Documentation complÃ¨te](https://htmlpreview.github.io/?https://github.com/ClementV78/prompt2prod/blob/main/docs/html/index.html)** - Interface d'accueil

## ğŸ”§ DÃ©veloppement

### DÃ©ploiement manuel (aprÃ¨s GitHub Actions build)

```bash
# 1. RÃ©cupÃ©rer l'image buildÃ©e par GitHub Actions
export IMAGE_TAG="ghcr.io/clementv78/prompt2prod:$(git rev-parse HEAD)"
docker pull $IMAGE_TAG

# 2. DÃ©ployer avec la nouvelle image
envsubst < k8s/base/app/deployment.yaml | kubectl apply -f -
kubectl apply -R -f k8s/base/

# 3. VÃ©rifier le rollout
kubectl rollout status deployment/app -n prompt2prod

# 4. AccÃ¨s aux logs
kubectl logs -f deployment/app -n prompt2prod
```

### DÃ©ploiement automatique (self-hosted runner)

Pour un dÃ©ploiement automatique, voir la [documentation du self-hosted runner](docs/SELF_HOSTED_RUNNER.md).

### Build local (dÃ©veloppement)

```bash
# Build et test local
docker build -t prompt2prod:dev -f docker/Dockerfile .
docker run --rm -p 8000:8000 prompt2prod:dev
```

## âš¡ Exemple d'utilisation

```bash
# GÃ©nÃ©ration avec modÃ¨le local (recommandÃ©: phi3:mini)
curl -X POST "http://localhost:8080/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a Python FastAPI hello world",
    "model": "phi3:mini", 
    "mode": "local"
  }'

# GÃ©nÃ©ration avec modÃ¨le cloud (OpenAI)
curl -X POST "http://localhost:8080/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a complex microservice architecture",
    "model": "gpt-4o-mini", 
    "mode": "cloud"
  }'

# Interface Swagger
open http://localhost:8080/docs
```

## ğŸ“„ Licence

MIT

## ğŸš€ Status

âœ… **Production Ready** - Architecture DevOps moderne avec patterns cloud-native

---

**Note**: Ce projet dÃ©montre une architecture DevOps complÃ¨te intÃ©grant l'IA locale sans dÃ©pendances externes payantes.